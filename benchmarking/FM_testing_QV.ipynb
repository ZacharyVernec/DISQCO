{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2938908441.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from circuits.QA\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from qiskit import transpile\n",
    "from qiskit.circuit.library import QuantumVolume\n",
    "\n",
    "from src.GCP_hypergraph import QuantumCircuitHyperGraph\n",
    "from circuits.cp_fraction import cp_fraction\n",
    "from circuits.QAOA import QAOA_random\n",
    "from src.FM_main import *\n",
    "from src.multilevel_FM import *\n",
    "\n",
    "def build_circuit(num_qubits,fraction,group_gates=True):\n",
    "    try:\n",
    "        circuit = cp_fraction(num_qubits,num_qubits,fraction)\n",
    "        # circuit = QFT(num_qubits,do_swaps=False)\n",
    "        # circuit = QAOA_random(num_qubits,0.5,reps=1)\n",
    "        # circuit = QuantumVolume(num_qubits,num_qubits)\n",
    "            \n",
    "        circuit = transpile(circuit, basis_gates = ['u','cp'])\n",
    "        graph = QuantumCircuitHyperGraph(num_qubits,depth=circuit.depth())\n",
    "        graph.map_circuit_to_hypergraph(circuit,group_gates=group_gates)\n",
    "\n",
    "        return graph\n",
    "    except IndexError:\n",
    "        print(\"Conversion issue, retrying\")\n",
    "        return build_circuit(num_qubits,fraction,group_gates=True)\n",
    "    except TypeError:\n",
    "        print(\"Conversion issue, retrying\")\n",
    "        return build_circuit(num_qubits,fraction,group_gates=True)\n",
    "\n",
    "###############################################################################\n",
    "# Set up JSON file for storing *all* iteration results (detailed data)\n",
    "###############################################################################\n",
    "detailed_filename = \"benchmark_results_FM_QV_5it.json\"\n",
    "\n",
    "if os.path.exists(detailed_filename):\n",
    "    with open(detailed_filename, \"r\") as f:\n",
    "        detailed_results = json.load(f)\n",
    "else:\n",
    "    detailed_results = []\n",
    "\n",
    "###############################################################################\n",
    "# Set up JSON file for *aggregated* results (mean cost/time)\n",
    "###############################################################################\n",
    "means_filename = \"benchmark_means_FM_QV_5it.json\"\n",
    "\n",
    "if os.path.exists(means_filename):\n",
    "    with open(means_filename, \"r\") as f:\n",
    "        mean_results = json.load(f)\n",
    "else:\n",
    "    mean_results = []\n",
    "\n",
    "sizes = range(16, 49, 8)\n",
    "\n",
    "for i, num_qubits in enumerate(sizes):\n",
    "    # For each increase of 8 qubits, increase the number of partitions by 1\n",
    "    num_partitions = 2 + i\n",
    "\n",
    "    # Create an All-to-All network\n",
    "    qpu_info = [int(num_qubits / num_partitions) + 1 for _ in range(num_partitions)]\n",
    "    \n",
    "    # Sweep the fraction parameter from 0.1 to 0.9\n",
    "        # Collect data for computing means across 10 iterations\n",
    "    iteration_data = []\n",
    "    for iteration in range(5):\n",
    "        \n",
    "        # -------------------------\n",
    "        # 1. Define/redefine circuit\n",
    "        # -------------------------\n",
    "\n",
    "        # base_graph = build_circuit(num_qubits,fraction=fraction,group_gates=True)\n",
    "        circuit = QuantumVolume(num_qubits,num_qubits)\n",
    "        circuit = transpile(circuit, basis_gates = ['u','cp'])\n",
    "        base_graph = QuantumCircuitHyperGraph(num_qubits,depth=circuit.depth())\n",
    "        base_graph.map_circuit_to_hypergraph(circuit,group_gates=True)\n",
    "        depth = base_graph.depth\n",
    "        initial_assignment = set_initial_partitions(qpu_info,num_qubits, depth ,num_partitions, reduced=True)\n",
    "        \n",
    "        # -------------------------\n",
    "        # 2. Fine-grained partitioning\n",
    "        # -------------------------\n",
    "        graph_list = [base_graph]\n",
    "        mapping_list = [{i : set([i]) for i in range(depth)}]\n",
    "\n",
    "        assignment_list_f, cost_list_f, time_list_f = multilevel_FM(graph_list,\n",
    "                                                                mapping_list,\n",
    "                                                                initial_assignment,\n",
    "                                                                qpu_info,\n",
    "                                                                limit = num_qubits*depth/8,\n",
    "                                                                pass_list= [50],\n",
    "                                                                stochastic=True,\n",
    "                                                                lock_nodes=False,\n",
    "                                                                log = False,\n",
    "                                                                add_initial = False,\n",
    "                                                                costs = None)\n",
    "        total_time_f = sum(time_list_f)\n",
    "        min_cost_f = min(cost_list_f)\n",
    "        # -------------------------\n",
    "        # 3. Window-based refinement\n",
    "        # -------------------------\n",
    "\n",
    "        assignment_list_w, cost_list_w, time_list_w = MLFM_window(base_graph, \n",
    "            num_levels=8,\n",
    "            initial_assignment=initial_assignment,  \n",
    "            qpu_info= qpu_info, \n",
    "            limit = None, \n",
    "            pass_list= None, \n",
    "            stochastic=True, \n",
    "            lock_nodes=True,\n",
    "            log = False,\n",
    "            add_initial = False,\n",
    "            costs = None)\n",
    "        \n",
    "        total_time_w = sum(time_list_w)\n",
    "        min_cost_w = min(cost_list_w)\n",
    "\n",
    "        \n",
    "        # -------------------------\n",
    "        # 4. Block refinement\n",
    "        # -------------------------\n",
    "        assignment_list_b, cost_list_b, time_list_b = MLFM_blocks(base_graph,\n",
    "                                        num_blocks=8,\n",
    "                                        initial_assignment=initial_assignment,  \n",
    "                                        qpu_info= qpu_info, \n",
    "                                        limit = None, \n",
    "                                        pass_list= None, \n",
    "                                        stochastic=True, \n",
    "                                        lock_nodes=True,\n",
    "                                        log = False,\n",
    "                                        add_initial = False,\n",
    "                                        costs = None,\n",
    "                                        full = False)\n",
    "        \n",
    "        total_time_b = sum(time_list_b)\n",
    "        min_cost_b = min(cost_list_b)\n",
    "        \n",
    "        # -------------------------\n",
    "        # 5. Recursive refinement\n",
    "        # -------------------------\n",
    "        assignment_list_r, cost_list_r, time_list_r = MLFM_recursive(base_graph,\n",
    "                                    initial_assignment,  \n",
    "                                    qpu_info, \n",
    "                                    limit = None, \n",
    "                                    pass_list= None, \n",
    "                                    stochastic=True, \n",
    "                                    lock_nodes=False,\n",
    "                                    log = False,\n",
    "                                    add_initial = False,\n",
    "                                    costs = None)\n",
    "        \n",
    "        total_time_r = sum(time_list_r)\n",
    "        min_cost_r = min(cost_list_r)\n",
    "\n",
    "        \n",
    "        # -------------------------\n",
    "        # 6. Store iteration-level results\n",
    "        # -------------------------\n",
    "        result_entry = {\n",
    "            \"num_qubits\": num_qubits,\n",
    "            \"num_partitions\": num_partitions,\n",
    "            \"iteration\": iteration,\n",
    "            \"f_cost\": min_cost_f,\n",
    "            \"w_cost\": min_cost_w,\n",
    "            \"b_cost\": min_cost_b,\n",
    "            \"r_cost\":  min_cost_r,\n",
    "            \"time_f\": total_time_f,\n",
    "            \"time_w\": total_time_w,\n",
    "            \"time_b\": total_time_b,\n",
    "            \"time_r\": total_time_r,\n",
    "        }\n",
    "        \n",
    "        detailed_results.append(result_entry)\n",
    "        iteration_data.append(result_entry)\n",
    "        \n",
    "        # Update detailed JSON right away\n",
    "        with open(detailed_filename, \"w\") as f:\n",
    "            json.dump(detailed_results, f, indent=2)\n",
    "    \n",
    "    # ---------------------------------------------------------------------\n",
    "    # After 10 iterations, compute the means and log them\n",
    "    # ---------------------------------------------------------------------\n",
    "    f_cost_list = [x[\"f_cost\"] for x in iteration_data]\n",
    "    w_cost_list = [x[\"w_cost\"] for x in iteration_data]\n",
    "    b_cost_list = [x[\"b_cost\"] for x in iteration_data]\n",
    "    r_cost_list = [x[\"r_cost\"] for x in iteration_data]\n",
    "    \n",
    "    f_time_list = [x[\"time_f\"] for x in iteration_data]\n",
    "    w_time_list = [x[\"time_w\"] for x in iteration_data]\n",
    "    b_time_list = [x[\"time_b\"] for x in iteration_data]\n",
    "    r_time_list = [x[\"time_r\"] for x in iteration_data]\n",
    "    \n",
    "    mean_f_cost = float(np.mean(f_cost_list))\n",
    "    mean_w_cost = float(np.mean(w_cost_list))\n",
    "    mean_b_cost = float(np.mean(b_cost_list))\n",
    "    mean_r_cost = float(np.mean(r_cost_list))\n",
    "    \n",
    "    mean_f_time = float(np.mean(f_time_list))\n",
    "    mean_w_time = float(np.mean(w_time_list))\n",
    "    mean_b_time = float(np.mean(b_time_list))\n",
    "    mean_r_time = float(np.mean(r_time_list))\n",
    "    \n",
    "    # Print to console for quick logging\n",
    "    print(\"=============================================\")\n",
    "    print(f\"Finished 10 iterations for:\")\n",
    "    print(f\"  # Qubits: {num_qubits}, # Partitions: {num_partitions}\")\n",
    "    print(\"Mean Costs:\")\n",
    "    print(f\"  `Fine`:    {mean_f_cost:.3f}\")\n",
    "    print(f\"  Window: {mean_w_cost:.3f}\")\n",
    "    print(f\"  Block: {mean_b_cost:.3f}\")\n",
    "    print(f\"  Recursive:{mean_r_cost:.3f}\")\n",
    "    print(\"Mean Times (s):\")\n",
    "    print(f\"  Fine:    {mean_f_time:.3f}\")\n",
    "    print(f\"  Window: {mean_w_time:.3f}\")\n",
    "    print(f\"  Block: {mean_b_time:.3f}\")\n",
    "    print(f\"  Recursive:{mean_r_time:.3f}\")\n",
    "    print(\"=============================================\")\n",
    "    \n",
    "    # Store the aggregated means in a separate JSON\n",
    "    mean_entry = {\n",
    "        \"num_qubits\": num_qubits,\n",
    "        \"num_partitions\": num_partitions,\n",
    "        \"mean_f_cost\": mean_f_cost,\n",
    "        \"mean_w_cost\": mean_w_cost,\n",
    "        \"mean_b_cost\": mean_b_cost,\n",
    "        \"mean_r_cost\": mean_r_cost,\n",
    "        \"mean_f_time\": mean_f_time,\n",
    "        \"mean_w_time\": mean_w_time,\n",
    "        \"mean_b_time\": mean_b_time,\n",
    "        \"mean_r_time\": mean_r_time,\n",
    "    }\n",
    "    \n",
    "    mean_results.append(mean_entry)\n",
    "    \n",
    "    # Update the means JSON file\n",
    "    with open(means_filename, \"w\") as f:\n",
    "        json.dump(mean_results, f, indent=2)\n",
    "\n",
    "print(\"Benchmarking completed. Detailed results saved to\", detailed_filename)\n",
    "print(\"Aggregated means saved to\", means_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
