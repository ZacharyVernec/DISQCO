{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Number of levels: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 92\u001b[0m\n\u001b[1;32m     87\u001b[0m min_cost_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(cost_list_f)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# 3. Window-based refinement\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m assignment_list_w, cost_list_w, time_list_w, pass_time_list_w, pass_cost_list_w \u001b[38;5;241m=\u001b[39m \u001b[43mMLFM_window_bench\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_assignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_assignment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqpu_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqpu_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpasses_per_level\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_levels\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstochastic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstochastic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlock_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_initial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m total_time_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(time_list_w)\n\u001b[1;32m    105\u001b[0m min_cost_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(cost_list_w)\n",
      "File \u001b[0;32m~/MLQCP_FM/src/MLFM_GCP/partitioning/FM/multilevel_FM_bench.py:248\u001b[0m, in \u001b[0;36mMLFM_window_bench\u001b[0;34m(graph, num_levels, initial_assignment, qpu_info, limit, pass_list, stochastic, lock_nodes, log, add_initial, costs)\u001b[0m\n\u001b[1;32m    243\u001b[0m     pass_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mlen\u001b[39m(graph_list)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of levels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(graph_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 248\u001b[0m assignment_list, cost_list, time_list, pass_time_list, pass_cost_list \u001b[38;5;241m=\u001b[39m \u001b[43mmultilevel_FM_bench\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoarsened_hypergraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmapping_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43minitial_assignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_assignment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mqpu_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqpu_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mpass_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mstochastic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstochastic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlock_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43madd_initial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_initial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcosts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcosts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assignment_list, cost_list, time_list,pass_time_list, pass_cost_list\n",
      "File \u001b[0;32m~/MLQCP_FM/src/MLFM_GCP/partitioning/FM/multilevel_FM_bench.py:91\u001b[0m, in \u001b[0;36mmultilevel_FM_bench\u001b[0;34m(coarsened_hypergraphs, mapping_list, initial_assignment, qpu_info, limit, pass_list, stochastic, lock_nodes, log, add_initial, costs, level_limit)\u001b[0m\n\u001b[1;32m     89\u001b[0m passes \u001b[38;5;241m=\u001b[39m pass_list[i]\n\u001b[1;32m     90\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 91\u001b[0m best_cost_pass, best_assignment, cost_list, time_list \u001b[38;5;241m=\u001b[39m \u001b[43mrun_FM_bench\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypergraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# This stage's coarsened hypergraph\u001b[39;49;00m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_assignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_assignment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqpu_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqpu_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_partitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_gain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstochastic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstochastic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactive_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactive_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_initial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_initial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcosts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcosts\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    106\u001b[0m level_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/MLQCP_FM/src/MLFM_GCP/partitioning/FM/FM_main.py:171\u001b[0m, in \u001b[0;36mrun_FM_bench\u001b[0;34m(hypergraph, initial_assignment, qpu_info, num_partitions, limit, max_gain, passes, stochastic, active_nodes, log, add_initial, costs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(passes):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# print(f\"Pass number: {n}\")\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 171\u001b[0m     assignment_list, gain_list \u001b[38;5;241m=\u001b[39m \u001b[43mFM_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhypergraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_gain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_assignment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqpu_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_nodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mactive_nodes\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    176\u001b[0m     time_list\u001b[38;5;241m.\u001b[39mappend(end\u001b[38;5;241m-\u001b[39mstart)\n",
      "File \u001b[0;32m~/MLQCP_FM/src/MLFM_GCP/partitioning/FM/FM_main.py:35\u001b[0m, in \u001b[0;36mFM_pass\u001b[0;34m(hypergraph, max_gain, assignment, num_partitions, qpu_info, costs, limit, active_nodes)\u001b[0m\n\u001b[1;32m     33\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m h \u001b[38;5;241m<\u001b[39m limit:\n\u001b[0;32m---> 35\u001b[0m     action, gain \u001b[38;5;241m=\u001b[39m \u001b[43mfind_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuckets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlock_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_gain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/MLQCP_FM/src/MLFM_GCP/partitioning/FM/FM_methods.py:192\u001b[0m, in \u001b[0;36mfind_action\u001b[0;34m(buckets, lock_dict, spaces, max_gain)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m action, gain\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m# print(\"Locked\")\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mbucket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# buckets[i].remove(action)\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     length \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from qiskit import transpile\n",
    "from MLFM_GCP.graphs.GCP_hypergraph import QuantumCircuitHyperGraph\n",
    "from MLFM_GCP.circuits.cp_fraction import cp_fraction\n",
    "from MLFM_GCP.circuits.QAOA import QAOA_random\n",
    "from MLFM_GCP.partitioning.FM.FM_main import *\n",
    "from MLFM_GCP.partitioning.FM.multilevel_FM_bench import *\n",
    "\n",
    "from qiskit.circuit.library import QFT, QuantumVolume\n",
    "\n",
    "\n",
    "detailed_filename = \"benchmark_results_MLFM_comparison.json\"\n",
    "\n",
    "exploration = 'explore'\n",
    "exploration = 'exploit'\n",
    "\n",
    "if exploration == 'explore':\n",
    "    stochastic = True\n",
    "else:\n",
    "    stochastic = False\n",
    "\n",
    "# if os.path.exists(detailed_filename):\n",
    "#     with open(detailed_filename, \"r\") as f:\n",
    "#         detailed_results = json.load(f)\n",
    "# else:\n",
    "\n",
    "detailed_results = []\n",
    "\n",
    "sizes = [64]\n",
    "\n",
    "passes_per_level = 10\n",
    "fractions = [0.5]\n",
    "num_partitions_list = [2]\n",
    "\n",
    "for i, num_qubits in enumerate(sizes):\n",
    "    # For each increase of 8 qubits, increase the number of partitions by 1\n",
    "    num_partitions = num_partitions_list[i]\n",
    "\n",
    "    # Create an All-to-All network\n",
    "    qpu_info = [int(num_qubits / num_partitions) + 1 for _ in range(num_partitions)]\n",
    "    \n",
    "    # Sweep the fraction parameter from 0.1 to 0.9\n",
    "    for fraction in fractions:\n",
    "        \n",
    "        # Collect data for computing means across 10 iterations\n",
    "        iteration_data = []\n",
    "        \n",
    "        for iteration in range(1):\n",
    "            \n",
    "            # -------------------------\n",
    "            # 1. Define/redefine circuit\n",
    "            # -------------------------\n",
    "            circuit = cp_fraction(num_qubits, num_qubits, fraction)\n",
    "\n",
    "            # circuit = QFT(num_qubits, do_swaps=False)\n",
    "            # circuit = QuantumVolume(num_qubits, num_qubits, seed=0)\n",
    "            # circuit = QAOA_random(num_qubits, prob = 0.5, reps =1)\n",
    "            circuit = transpile(circuit, basis_gates=['cp', 'u'])\n",
    "            base_graph = QuantumCircuitHyperGraph(circuit, group_gates= True, anti_diag = True)\n",
    "            depth = base_graph.depth\n",
    "            initial_assignment = set_initial_partitions(qpu_info,num_qubits, depth ,num_partitions, reduced=True)\n",
    "            num_levels = int(np.ceil(np.log2(depth)))\n",
    "            print(num_levels)\n",
    "\n",
    "            limit = num_qubits * depth\n",
    "            # -------------------------\n",
    "            # 2. Fine-grained partitioning\n",
    "            # -------------------------\n",
    "            graph_list = [base_graph]\n",
    "            mapping_list = [{i : set([i]) for i in range(depth)}]\n",
    "\n",
    "            assignment_list_f, cost_list_f, time_list_f, pass_time_list_f, pass_cost_list_f = multilevel_FM_bench(graph_list,\n",
    "                                                                    mapping_list,\n",
    "                                                                    initial_assignment,\n",
    "                                                                    qpu_info,\n",
    "                                                                    limit=limit,\n",
    "                                                                    pass_list=[passes_per_level * (num_levels + 1)],\n",
    "                                                                    stochastic=stochastic,\n",
    "                                                                    lock_nodes=False,\n",
    "                                                                    log=False,\n",
    "                                                                    add_initial=False,\n",
    "                                                                    costs=None)\n",
    "            total_time_f = sum(time_list_f)\n",
    "            min_cost_f = min(cost_list_f)\n",
    "            # -------------------------\n",
    "            # 3. Window-based refinement\n",
    "            # -------------------------\n",
    "\n",
    "            assignment_list_w, cost_list_w, time_list_w, pass_time_list_w, pass_cost_list_w = MLFM_window_bench(base_graph, \n",
    "                num_levels=num_levels,\n",
    "                initial_assignment=initial_assignment,  \n",
    "                qpu_info=qpu_info, \n",
    "                limit=limit, \n",
    "                pass_list=[passes_per_level]*(num_levels+1), \n",
    "                stochastic=stochastic, \n",
    "                lock_nodes=False,\n",
    "                log = False,\n",
    "                add_initial = False,\n",
    "                costs = None)\n",
    "            \n",
    "            total_time_w = sum(time_list_w)\n",
    "            min_cost_w = min(cost_list_w)\n",
    "\n",
    "            \n",
    "            # -------------------------\n",
    "            # 4. Block refinement\n",
    "            # -------------------------\n",
    "            assignment_list_b, cost_list_b, time_list_b, pass_time_list_b, pass_cost_list_b = MLFM_blocks_bench(base_graph,\n",
    "                                            num_levels=num_levels,\n",
    "                                            initial_assignment=initial_assignment,  \n",
    "                                            qpu_info=qpu_info, \n",
    "                                            limit=limit, \n",
    "                                            pass_list=[passes_per_level] * (num_levels + 1), \n",
    "                                            stochastic=stochastic, \n",
    "                                            lock_nodes=False,\n",
    "                                            log = False,\n",
    "                                            add_initial = False,\n",
    "                                            costs = None,\n",
    "                                            full = False)\n",
    "            \n",
    "            total_time_b = sum(time_list_b)\n",
    "            min_cost_b = min(cost_list_b)\n",
    "            \n",
    "            # -------------------------\n",
    "            # 5. Recursive refinement\n",
    "            # -------------------------\n",
    "            assignment_list_r, cost_list_r, time_list_r, pass_time_list_r, pass_cost_list_r = MLFM_recursive_bench(base_graph,\n",
    "                                        initial_assignment,  \n",
    "                                        qpu_info, \n",
    "                                        limit = limit, \n",
    "                                        pass_list = [passes_per_level]*(num_levels+1), \n",
    "                                        stochastic=stochastic, \n",
    "                                        lock_nodes=False,\n",
    "                                        log = False,\n",
    "                                        add_initial = False,\n",
    "                                        costs = None)\n",
    "            \n",
    "            total_time_r = sum(time_list_r)\n",
    "            min_cost_r = min(cost_list_r)\n",
    "\n",
    "            print(\"Min cost f: \", min_cost_f)\n",
    "            print(\"Min cost w: \", min_cost_w)\n",
    "            print(\"Min cost b: \", min_cost_b)\n",
    "            print(\"Min cost r: \", min_cost_r)\n",
    "\n",
    "            \n",
    "            # -------------------------\n",
    "            # 6. Store iteration-level results\n",
    "            # -------------------------\n",
    "            result_entry = {\n",
    "                \"num_qubits\": num_qubits,\n",
    "                \"num_partitions\": num_partitions,\n",
    "                \"fraction\": fraction,\n",
    "                \"pass_cost_list_f\" : pass_cost_list_f,\n",
    "                \"pass_cost_list_w\" : pass_cost_list_w,\n",
    "                \"pass_cost_list_b\" : pass_cost_list_b,\n",
    "                \"pass_cost_list_r\" : pass_cost_list_r,\n",
    "                \"pass_time_list_f\" : pass_time_list_f,\n",
    "                \"pass_time_list_w\" : pass_time_list_w,\n",
    "                \"pass_time_list_b\" : pass_time_list_b,\n",
    "                \"pass_time_list_r\" : pass_time_list_r,\n",
    "            }\n",
    "            \n",
    "            detailed_results.append(result_entry)\n",
    "            iteration_data.append(result_entry)\n",
    "            \n",
    "            # Update detailed JSON right away\n",
    "            with open(detailed_filename, \"w\") as f:\n",
    "                json.dump(detailed_results, f, indent=2)\n",
    "        \n",
    "\n",
    "print(\"Benchmarking completed. Detailed results saved to\", detailed_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'num_qubits': 128, 'num_partitions': 2, 'fraction': 0.5, 'pass_cost_list_f': [[1275, 1274, 1273, 1272, 1271, 1270, 1270, 1268, 1267, 1267, 1267, 1267, 1267, 1266, 1266, 1266, 1266, 1265, 1265, 1265, 1264, 1263, 1262, 1262, 1262, 1262, 1262, 1262, 1261, 1261, 1260, 1259, 1259, 1258, 1258, 1258, 1258, 1258, 1258, 1258]], 'pass_cost_list_w': [[1161, 1125, 1106, 1101, 1101], [1094, 1091, 1090, 1090, 1090], [1087, 1087, 1087, 1086, 1084], [1077, 1077, 1076, 1076, 1076], [1064, 1062, 1061, 1061, 1060], [1056, 1054, 1054, 1052, 1052], [1049, 1047, 1047, 1046, 1046], [1045, 1045, 1045, 1044, 1044]], 'pass_cost_list_b': [[1150, 1099, 1086, 1077, 1078], [1058, 1045, 1039, 1033, 1033], [1026, 1026, 1026, 1026, 1026], [1023, 1023, 1022, 1022, 1022], [1018, 1018, 1018, 1018, 1017], [1017, 1016, 1015, 1014, 1014], [1013, 1013, 1012, 1011, 1011], [1011, 1011, 1011, 1011, 1011]], 'pass_cost_list_r': [[1148, 1096, 1082, 1079, 1075], [1045, 1037, 1038, 1037, 1037], [1015, 1005, 999, 995, 989], [974, 971, 965, 962, 962], [944, 939, 933, 931, 928], [919, 917, 916, 916, 916], [905, 904, 903, 902, 899], [899, 899, 899, 899, 899]], 'pass_time_list_f': [[0.16733813285827637, 0.1674818992614746, 0.16495704650878906, 0.16570377349853516, 0.16444611549377441, 0.16892504692077637, 0.16732501983642578, 0.1645200252532959, 0.1643822193145752, 0.1649782657623291, 0.16473793983459473, 0.16355299949645996, 0.17482495307922363, 0.16468405723571777, 0.1643061637878418, 0.1633131504058838, 0.16377592086791992, 0.1639251708984375, 0.16953206062316895, 0.1703939437866211, 0.1648120880126953, 0.16419410705566406, 0.1637592315673828, 0.1637411117553711, 0.16462278366088867, 0.17212414741516113, 0.1659259796142578, 0.16266822814941406, 0.1637728214263916, 0.1639559268951416, 0.16435909271240234, 0.17069315910339355, 0.17048120498657227, 0.16509628295898438, 0.16443395614624023, 0.16519618034362793, 0.16417503356933594, 0.16370296478271484, 0.17369985580444336, 0.1653280258178711]], 'pass_time_list_w': [[0.03173494338989258, 0.023094654083251953, 0.017222881317138672, 0.01717519760131836, 0.015743017196655273], [0.039267778396606445, 0.03575396537780762, 0.03859400749206543, 0.03761100769042969, 0.03450131416320801], [0.05885791778564453, 0.05526089668273926, 0.05647706985473633, 0.054793357849121094, 0.05600094795227051], [0.08019685745239258, 0.07665824890136719, 0.07608985900878906, 0.07716989517211914, 0.07859206199645996], [0.10948300361633301, 0.10166764259338379, 0.0995330810546875, 0.09995222091674805, 0.1003568172454834], [0.12168717384338379, 0.12125611305236816, 0.1222391128540039, 0.12256717681884766, 0.12425398826599121], [0.14725685119628906, 0.14410686492919922, 0.14440393447875977, 0.14395809173583984, 0.1446070671081543], [0.4763331413269043, 0.16381072998046875, 0.1693880558013916, 0.16167402267456055, 0.16271686553955078]], 'pass_time_list_b': [[0.02898883819580078, 0.025751113891601562, 0.026500701904296875, 0.026247024536132812, 0.02628493309020996], [0.04228687286376953, 0.04893994331359863, 0.041773080825805664, 0.03450274467468262, 0.03388714790344238], [0.05667686462402344, 0.053826093673706055, 0.05683612823486328, 0.055119991302490234, 0.054480791091918945], [0.07839488983154297, 0.0772390365600586, 0.07536005973815918, 0.07702875137329102, 0.07501387596130371], [0.10203790664672852, 0.09586143493652344, 0.11545014381408691, 0.10481095314025879, 0.10488390922546387], [0.12909197807312012, 0.12233209609985352, 0.12372994422912598, 0.11896014213562012, 0.11623072624206543], [0.14980125427246094, 0.15421199798583984, 0.1380453109741211, 0.1374058723449707, 0.1601400375366211], [0.1676321029663086, 0.16650176048278809, 0.17459487915039062, 0.16649794578552246, 0.1612992286682129]], 'pass_time_list_r': [[0.10374903678894043, 0.1267240047454834, 0.12423086166381836, 0.10287785530090332, 0.10143399238586426], [0.09736323356628418, 0.09014511108398438, 0.09651899337768555, 0.09043312072753906, 0.09077620506286621], [0.09154391288757324, 0.1736130714416504, 0.0986928939819336, 0.09166407585144043, 0.08696126937866211], [0.09307003021240234, 0.08692407608032227, 0.08801579475402832, 0.10064315795898438, 0.09023094177246094], [0.09818315505981445, 0.09307217597961426, 0.0933370590209961, 0.0983891487121582, 0.09289884567260742], [0.10914111137390137, 0.10386276245117188, 0.10491108894348145, 0.10411190986633301, 0.10501599311828613], [0.12904119491577148, 0.12231779098510742, 0.13274192810058594, 0.12389922142028809, 0.12328791618347168], [0.1707749366760254, 0.1626298427581787, 0.16856074333190918, 0.16423797607421875, 0.17550396919250488]]}]\n",
      "1 8 8 8\n"
     ]
    }
   ],
   "source": [
    "# with open(detailed_filename, \"r\") as f:\n",
    "\n",
    "#     data = json.load(f)\n",
    "\n",
    "data = detailed_results\n",
    "\n",
    "print(data)\n",
    "\n",
    "for entry in data:\n",
    "    cost_list_f = entry[\"pass_cost_list_f\"]\n",
    "    cost_list_w = entry[\"pass_cost_list_w\"]\n",
    "    cost_list_b = entry[\"pass_cost_list_b\"]\n",
    "    cost_list_r = entry[\"pass_cost_list_r\"]\n",
    "    print(len(cost_list_f), len(cost_list_w), len(cost_list_b), len(cost_list_r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n"
     ]
    }
   ],
   "source": [
    "for entry in data:\n",
    "    time_list_f = copy.deepcopy(entry['pass_time_list_f'])\n",
    "    time_list_w = copy.deepcopy(entry['pass_time_list_w'])\n",
    "    time_list_b = copy.deepcopy(entry['pass_time_list_b'])\n",
    "    time_list_r = copy.deepcopy(entry['pass_time_list_r'])\n",
    "    counter = 0\n",
    "\n",
    "    cumulative_time_f = 0\n",
    "    cumulative_time_w = 0\n",
    "    cumulative_time_b = 0\n",
    "    cumulative_time_r = 0\n",
    "    \n",
    "    for i in range(len(time_list_w)):\n",
    "        for j in range(len(time_list_w[i])):\n",
    "            print(i,j)\n",
    "            prev_time_f = time_list_f[0][counter] \n",
    "            prev_time_w = time_list_w[i][j]\n",
    "            prev_time_b = time_list_b[i][j]\n",
    "            prev_time_r = time_list_r[i][j]\n",
    "\n",
    "            cumulative_time_f += prev_time_f\n",
    "            cumulative_time_w += prev_time_w\n",
    "            cumulative_time_b += prev_time_b\n",
    "            cumulative_time_r += prev_time_r\n",
    "\n",
    "            time_list_f[0][counter] = cumulative_time_f\n",
    "            time_list_w[i][j] = cumulative_time_w\n",
    "            time_list_b[i][j] = cumulative_time_b\n",
    "            time_list_r[i][j] = cumulative_time_r\n",
    "\n",
    "            counter += 1\n",
    "    \n",
    "    entry['cumulative_time_list_f'] = time_list_f\n",
    "    entry['cumulative_time_list_w'] = time_list_w\n",
    "    entry['cumulative_time_list_b'] = time_list_b\n",
    "    entry['cumulative_time_list_r'] = time_list_r\n",
    "\n",
    "\n",
    "with open(detailed_filename, \"w\") as f:\n",
    "    json.dump(data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "data = detailed_results\n",
    "def flatten_pass_lists(nested_list):\n",
    "\n",
    "    return list(itertools.chain.from_iterable(nested_list))\n",
    "with open(\"dat_files/coarseners_256_2part_cost.dat\", \"w\") as f:\n",
    "    f.write(\"pass f w b r\\n\")\n",
    "    pass_cost_list_f = flatten_pass_lists(data[0]['pass_cost_list_f'])\n",
    "    pass_cost_list_w = flatten_pass_lists(data[0]['pass_cost_list_w'])\n",
    "    pass_cost_list_b = flatten_pass_lists(data[0]['pass_cost_list_b'])\n",
    "    pass_cost_list_r = flatten_pass_lists(data[0]['pass_cost_list_r'])\n",
    "    for i in range(len(pass_cost_list_f)):\n",
    "        f.write(f\"{i}\" + \" \" + str(pass_cost_list_f[i]) + \" \" + str(pass_cost_list_w[i]) + \" \" + str(pass_cost_list_b[i]) + \" \" + str(pass_cost_list_r[i]) + \"\\n\")\n",
    "    \n",
    "with open(\"dat_files/coarseners_256_2part_time.dat\", \"w\") as f:\n",
    "    f.write(\"pass f w b r\\n\")\n",
    "    cumulative_time_list_f = flatten_pass_lists(data[0]['cumulative_time_list_f'])\n",
    "    cumulative_time_list_w = flatten_pass_lists(data[0]['cumulative_time_list_w'])\n",
    "    cumulative_time_list_b = flatten_pass_lists(data[0]['cumulative_time_list_b'])\n",
    "    cumulative_time_list_r = flatten_pass_lists(data[0]['cumulative_time_list_r'])\n",
    "    for i in range(len(cumulative_time_list_f)):\n",
    "        f.write(f\"{i}\" + \" \" + str(cumulative_time_list_f[i]) + \" \" + str(cumulative_time_list_w[i]) + \" \" + str(cumulative_time_list_b[i]) + \" \" + str(cumulative_time_list_r[i]) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def flatten_pass_lists(nested_list):\n",
    "    \"\"\"\n",
    "    Flatten a list of lists into a single list.\n",
    "    E.g. [[1,2,3],[4,5],[6,7,8]] -> [1,2,3,4,5,6,7,8].\n",
    "    \"\"\"\n",
    "    return list(itertools.chain.from_iterable(nested_list))\n",
    "\n",
    "# 1) Load the JSON data from file (which is a list of dicts).\n",
    "with open(\"benchmark_results_MLFM_comparison.json\", \"r\") as f:\n",
    "    data_list = json.load(f)  # data_list is now a Python list of dicts\n",
    "\n",
    "# 2) Create a “long” list of records, one row per (method, pass_number).\n",
    "#    We’ll store them later in a pandas DataFrame.\n",
    "records = []\n",
    "\n",
    "# We know the methods are stored in these keys:\n",
    "method_keys = {\n",
    "    \"f\": \"pass_cost_list_f\",\n",
    "    \"w\": \"pass_cost_list_w\",\n",
    "    \"b\": \"pass_cost_list_b\",\n",
    "    \"r\": \"pass_cost_list_r\"\n",
    "}\n",
    "\n",
    "for entry in data_list:\n",
    "    num_qubits = entry[\"num_qubits\"]\n",
    "    num_partitions = entry[\"num_partitions\"]\n",
    "    fraction = entry[\"fraction\"]\n",
    "    \n",
    "    # For each method (f, w, b, r), flatten the pass costs into a single list\n",
    "    for method_label, json_key in method_keys.items():\n",
    "        if json_key not in entry:\n",
    "            # If the JSON doesn't have that key (unlikely), skip it\n",
    "            continue\n",
    "        \n",
    "        nested_pass_data = entry[json_key]  # e.g. pass_cost_list_w\n",
    "        flattened_costs = flatten_pass_lists(nested_pass_data)\n",
    "        \n",
    "        # Each entry in flattened_costs is a cost at pass i.\n",
    "        # We'll call pass i from 1..N to be consistent.\n",
    "        for i, cost in enumerate(flattened_costs):\n",
    "            # Build a dict record for this row\n",
    "            record = {\n",
    "                \"num_qubits\": num_qubits,\n",
    "                \"num_partitions\": num_partitions,\n",
    "                \"fraction\": fraction,\n",
    "                \"method\": method_label,\n",
    "                \"pass\": i + 1,\n",
    "                \"cost\": cost\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "# 3) Convert the big “records” list into a pandas DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 4) If you have multiple identical (num_qubits, num_partitions, fraction) sets\n",
    "#    and you want to average across them, group accordingly.\n",
    "#    For example, group by (method, pass) and also by (num_qubits, num_partitions, fraction)\n",
    "group_cols = [\"num_qubits\", \"num_partitions\", \"fraction\", \"method\", \"pass\"]\n",
    "grouped = df.groupby(group_cols).agg(\n",
    "    mean_cost=(\"cost\", \"mean\"),\n",
    "    std_cost=(\"cost\", \"std\")  # optional, for error bars\n",
    ").reset_index()\n",
    "\n",
    "# 5) Now pick which combination of (num_qubits, num_partitions, fraction) you want to plot.\n",
    "#    If you have only 1 unique set, that’s easy. Otherwise, you can loop over them.\n",
    "unique_combos = grouped[[\"num_qubits\", \"num_partitions\", \"fraction\"]].drop_duplicates()\n",
    "\n",
    "for _, combo_row in unique_combos.iterrows():\n",
    "    nq = combo_row[\"num_qubits\"]\n",
    "    nparts = combo_row[\"num_partitions\"]\n",
    "    frac = combo_row[\"fraction\"]\n",
    "    \n",
    "    # Filter just these qubits/partitions/fraction\n",
    "    subset = grouped[\n",
    "        (grouped[\"num_qubits\"] == nq)\n",
    "        & (grouped[\"num_partitions\"] == nparts)\n",
    "        & (grouped[\"fraction\"] == frac)\n",
    "    ]\n",
    "    \n",
    "    # We'll pivot or just iterate by “method” to plot each line\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    \n",
    "    methods = subset[\"method\"].unique()\n",
    "    \n",
    "    for m in methods:\n",
    "        sub2 = subset[subset[\"method\"] == m].sort_values(\"pass\")\n",
    "        \n",
    "        ax.errorbar(\n",
    "            sub2[\"pass\"],\n",
    "            sub2[\"mean_cost\"],\n",
    "            yerr=sub2[\"std_cost\"],          # comment this out if no error bars\n",
    "            label=f\"Method {m.upper()}\",    # e.g. F, W, B, R\n",
    "            marker='o', linestyle='-'\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(\"Pass number\")\n",
    "    ax.set_ylabel(\"Cost\")\n",
    "    ax.set_title(f\"{nq} qubits, {nparts} partitions, fraction={frac}\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show or save the figure:\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"plot_cost_{nq}q_{nparts}p_frac{frac}_{exploration}.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def flatten_pass_lists(nested_list):\n",
    "    \"\"\"\n",
    "    Flatten a list of lists into a single list.\n",
    "    E.g. [[1,2,3],[4,5],[6,7,8]] -> [1,2,3,4,5,6,7,8].\n",
    "    \"\"\"\n",
    "    return list(itertools.chain.from_iterable(nested_list))\n",
    "\n",
    "# 1) Load the JSON data from file (which is a list of dicts).\n",
    "with open(\"benchmark_results_MLFM_comparison.json\", \"r\") as f:\n",
    "    data_list = json.load(f)  # data_list is now a Python list of dicts\n",
    "\n",
    "# 2) Create a “long” list of records, one row per (method, pass_number).\n",
    "#    We’ll store them later in a pandas DataFrame.\n",
    "records = []\n",
    "\n",
    "# We know the methods are stored in these keys:\n",
    "method_keys = {\n",
    "    \"f\": \"cumulative_time_list_f\",\n",
    "    \"w\": \"cumulative_time_list_w\",\n",
    "    \"b\": \"cumulative_time_list_b\",\n",
    "    \"r\": \"cumulative_time_list_r\"\n",
    "}\n",
    "\n",
    "for entry in data_list:\n",
    "    num_qubits = entry[\"num_qubits\"]\n",
    "    num_partitions = entry[\"num_partitions\"]\n",
    "    fraction = entry[\"fraction\"]\n",
    "    \n",
    "    # For each method (f, w, b, r), flatten the pass costs into a single list\n",
    "    for method_label, json_key in method_keys.items():\n",
    "        if json_key not in entry:\n",
    "            # If the JSON doesn't have that key (unlikely), skip it\n",
    "            continue\n",
    "        \n",
    "        nested_pass_data = entry[json_key]  # e.g. pass_cost_list_w\n",
    "        flattened_costs = flatten_pass_lists(nested_pass_data)\n",
    "        \n",
    "        # Each entry in flattened_costs is a cost at pass i.\n",
    "        # We'll call pass i from 1..N to be consistent.\n",
    "        for i, cost in enumerate(flattened_costs):\n",
    "            # Build a dict record for this row\n",
    "            record = {\n",
    "                \"num_qubits\": num_qubits,\n",
    "                \"num_partitions\": num_partitions,\n",
    "                \"fraction\": fraction,\n",
    "                \"method\": method_label,\n",
    "                \"pass\": i + 1,\n",
    "                \"cost\": cost\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "# 3) Convert the big “records” list into a pandas DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 4) If you have multiple identical (num_qubits, num_partitions, fraction) sets\n",
    "#    and you want to average across them, group accordingly.\n",
    "#    For example, group by (method, pass) and also by (num_qubits, num_partitions, fraction)\n",
    "group_cols = [\"num_qubits\", \"num_partitions\", \"fraction\", \"method\", \"pass\"]\n",
    "grouped = df.groupby(group_cols).agg(\n",
    "    mean_cost=(\"cost\", \"mean\"),\n",
    "    std_cost=(\"cost\", \"std\")  # optional, for error bars\n",
    ").reset_index()\n",
    "\n",
    "# 5) Now pick which combination of (num_qubits, num_partitions, fraction) you want to plot.\n",
    "#    If you have only 1 unique set, that’s easy. Otherwise, you can loop over them.\n",
    "unique_combos = grouped[[\"num_qubits\", \"num_partitions\", \"fraction\"]].drop_duplicates()\n",
    "\n",
    "for _, combo_row in unique_combos.iterrows():\n",
    "    nq = combo_row[\"num_qubits\"]\n",
    "    nparts = combo_row[\"num_partitions\"]\n",
    "    frac = combo_row[\"fraction\"]\n",
    "    \n",
    "    # Filter just these qubits/partitions/fraction\n",
    "    subset = grouped[\n",
    "        (grouped[\"num_qubits\"] == nq)\n",
    "        & (grouped[\"num_partitions\"] == nparts)\n",
    "        & (grouped[\"fraction\"] == frac)\n",
    "    ]\n",
    "    \n",
    "    # We'll pivot or just iterate by “method” to plot each line\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    \n",
    "    methods = subset[\"method\"].unique()\n",
    "    \n",
    "    for m in methods:\n",
    "        sub2 = subset[subset[\"method\"] == m].sort_values(\"pass\")\n",
    "        \n",
    "        ax.errorbar(\n",
    "            sub2[\"pass\"],\n",
    "            sub2[\"mean_cost\"],\n",
    "            yerr=sub2[\"std_cost\"],          # comment this out if no error bars\n",
    "            label=f\"Method {m.upper()}\",    # e.g. F, W, B, R\n",
    "            marker='o', linestyle='-'\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(\"Pass number\")\n",
    "    ax.set_ylabel(\"Cost\")\n",
    "    ax.set_title(f\"{nq} qubits, {nparts} partitions, fraction={frac}\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show or save the figure:\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"_plot_time_{nq}q_{nparts}p_frac{frac}_{exploration}.png\")\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
